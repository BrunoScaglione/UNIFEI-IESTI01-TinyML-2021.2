{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_Cifar_10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiVBUpuHXEtw"
      },
      "source": [
        "# CNN to classify Cifar-10 dataset (Images)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt0KwMrt0I0n"
      },
      "source": [
        "So far, we saw how to build a Dense Neural Network (DNN) that classified images of digits (MNIST) or even fashion images (Fashion-MNIST). Here we will instead, recognize the 10 classes of CIFAR ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship' and 'truck'). There are some key differences between these two image datasets that we need to take into account. \n",
        "\n",
        "First, while MNIST were 28x28 monochrome images (1 color channel), CIFAR is 32x32 color images (3 color channels).\n",
        "\n",
        "Second, MNIST images are simple, containing just the object centered in the image, with no background. Conversely, CIFAR ones are not centered and can have the object with a background, such as airplanes that might have a cloudy sky behind them! Those differences are the main reason to use a CNN instead of a DNN. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WnUJoAL1pc2"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OQ_tVTaU3oo"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPogyxx5zt5J"
      },
      "source": [
        "## Import and Inspect Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNoaUYniNr5M"
      },
      "source": [
        "Cifar-10 repository: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiwcGwmLJVIc"
      },
      "source": [
        "cifar10 = datasets.cifar10\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x39c36sJ60N"
      },
      "source": [
        "print(train_images.shape, train_labels.shape)\n",
        "print(test_images.shape, test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzWNjl4JjiKU"
      },
      "source": [
        "- The image data shape is: `(#images, img_heigth, img_width, #channels)`, where channels are in RGB format (red, green, blue). \n",
        "- The labels shape is `(#images, label)`, where label goes from 0 to 9.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vopv6HetVj8y"
      },
      "source": [
        "train_images[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chqX49HIlW5c"
      },
      "source": [
        "plt.imshow(train_images[1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APDXWEtgKVfT"
      },
      "source": [
        "train_labels[1][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnUBI79QqL95"
      },
      "source": [
        "    The CIFAR labels happen to be arrays, which is why you need the extra index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oj0W6uIQxDm"
      },
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3O7Gy8-HU_5"
      },
      "source": [
        "class_names[9] # The List's index is the label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMfskv-rpXv-"
      },
      "source": [
        "idx = train_labels[1][0]\n",
        "class_names[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTRiPf7QKJWh"
      },
      "source": [
        "print(\"\\t\", class_names[train_labels[1][0]])\n",
        "plt.imshow(train_images[1])\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tubjj9IeLLWp"
      },
      "source": [
        " def plot_train_img(img, size=2): \n",
        "    label = train_labels[img][0]\n",
        "    plt.figure(figsize=(size,size))\n",
        "    print(\"Label {} - {}\".format(label, class_names[label]))\n",
        "    plt.imshow(train_images[img])\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw_E_Jp4M1fK"
      },
      "source": [
        "plot_train_img(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIww0M0YqFe3"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyjP8DsPp-rj"
      },
      "source": [
        "Note that images are in color, not centered and with different backgrounds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuPx6Fpg2-ER"
      },
      "source": [
        "## Preprocessing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDC5qAy9lxHI"
      },
      "source": [
        "test_images.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr1V-RwhJ0dC"
      },
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx8cqGbeWHB2"
      },
      "source": [
        "test_images.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8FbgbiaYpNV"
      },
      "source": [
        "plt.hist(train_labels[:5_000]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t5JF1P-Zm3f"
      },
      "source": [
        "val_images = train_images[:5_000]\n",
        "val_labels = train_labels[:5_000]\n",
        "print(val_images.shape, val_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxWvJq-BaB8s"
      },
      "source": [
        "train_images = train_images[5_000:]\n",
        "train_labels = train_labels[5_000:]\n",
        "print(train_images.shape, train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peWqyBAyaw5X"
      },
      "source": [
        "plt.hist(train_labels, alpha=0.5)\n",
        "plt.hist(val_labels, alpha=0.5)\n",
        "plt.hist(test_labels, alpha=0.5);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsvJeVm6_3VB"
      },
      "source": [
        "## Create Model Arquitecture and Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF73ofMGqt3p"
      },
      "source": [
        "On [Convolution layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D), \n",
        "- strides is an integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Default (1,1).\n",
        "- padding: one of \"valid\" or \"same\" (case-insensitive). Default = 'valid'.\n",
        "  - \"valid\" means no padding.  \n",
        "  - \"same\" results in padding with zeros evenly\n",
        "to the left/right or up/down of the input such that output has the same\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FTRI--UM5fK"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(\n",
        "    filters=32, \n",
        "    kernel_size=(3,3), \n",
        "    activation='relu', \n",
        "    input_shape=(32, 32, 3))\n",
        ")\n",
        "model.add(MaxPool2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxq2JU7dVIEX"
      },
      "source": [
        "LOSS = 'sparse_categorical_crossentropy'\n",
        "OPTIMIZER = 'adam'\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=OPTIMIZER,\n",
        "              loss=LOSS,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utH8U6ud44cY"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjAJ1xXz4pPE"
      },
      "source": [
        "NUM_EPOCHS = 20 #You can change this value if you like to experiment with it to get better accuracy"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1QKpQHFoVJI"
      },
      "source": [
        "# Fit the model\n",
        "history = model.fit(train_images, \n",
        "                    train_labels, \n",
        "                    epochs=NUM_EPOCHS, \n",
        "                    validation_data=(val_images, val_labels)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2VQKFylodzi"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.xlim([0,NUM_EPOCHS])\n",
        "plt.ylim([0.4,1.0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9KzYRI05g_M"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3eLN-JVvduA"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTW4IkOrwAAl"
      },
      "source": [
        "**Accuracy**\n",
        "- Train: 85% - 90%; \n",
        "- Validation: 68%-70% \n",
        "- Test: 66%-68%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD_r_qxxwF1M"
      },
      "source": [
        "predictions = np.argmax(model.predict(test_images), axis=-1)\n",
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWEA_ALv51P3"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hDUe5uq6PoX"
      },
      "source": [
        "print(classification_report(test_labels, predictions, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCwieAWB6yAh"
      },
      "source": [
        "confusion_matrix(test_labels,predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOkcOflwgoCR"
      },
      "source": [
        "class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3QJQ3ER7Btb"
      },
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.heatmap(confusion_matrix(test_labels,predictions), cmap='Blues', annot=True, fmt='g');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhL-fPKh7ryx"
      },
      "source": [
        "## Testing Model (Predicting)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8q8RbCU-i5g"
      },
      "source": [
        "plt.imshow(test_images[15]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GDFWkXG_H6Y"
      },
      "source": [
        "test_labels[15][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LshDRY7-8Iq"
      },
      "source": [
        "class_names[8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE6NF_wV-YfZ"
      },
      "source": [
        "test_images[15].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UGml1PgAYxS"
      },
      "source": [
        "The input Tensor shape should be: (num_images, width, height, color_channels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-bF-5tY_-RT"
      },
      "source": [
        "my_image = test_images[15]\n",
        "my_image = my_image.reshape(1,32,32,3)\n",
        "my_image.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGUt18nZ_WN8"
      },
      "source": [
        "img_pred = np.argmax(model.predict(my_image))\n",
        "class_names[img_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kojDXuqRBodN"
      },
      "source": [
        "def img_pred(img, size=4):\n",
        "    label = test_labels[img][0]\n",
        "    my_image = test_images[img]\n",
        "    plt.figure(figsize=(size,size))\n",
        "    plt.imshow(my_image)\n",
        "    my_image = my_image.reshape(1,32,32,3)\n",
        "    img_pred = np.argmax(model.predict(my_image))\n",
        "    pred_label = class_names[img_pred]\n",
        "    print(\" Label {} <=> Pred: {}\".format(class_names[label], pred_label))\n",
        "    plt.grid(False)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E11rQVtPCg5x"
      },
      "source": [
        "img_pred(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuCNz7aOfbTU"
      },
      "source": [
        "img_pred(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cswIMpUbfjWT"
      },
      "source": [
        "img_pred(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqzcgjh9fotR"
      },
      "source": [
        "img_pred(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d8CLZP5fwei"
      },
      "source": [
        "img_pred(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvNdviObf1oE"
      },
      "source": [
        "img_pred(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhnnOt7bgXGg"
      },
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty0qLh9ngk2-"
      },
      "source": [
        "!pwd # Linux command, shows where we are in CoLab's folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vN8z8vpgaup"
      },
      "source": [
        "model.save('cifar_10_model.h5')"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdEONve0j0ht"
      },
      "source": [
        "Use [Netron](https://netron.app) to visualize the model, hyperparameters, tensor shapes, etc. Netron is a viewer for neural network, deep learning and machine learning models (See [GitHub](https://github.com/lutzroeder/netron) for instructions about instalation in your desktop). "
      ]
    }
  ]
}